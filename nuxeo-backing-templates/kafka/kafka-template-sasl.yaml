apiVersion: v1
kind: Template
message: |-
  A Kafka Cluster has been created in your project.

  For more information about using this template, see https://github.com/nuxeo/nuxeo-openshift. This
  template was originally based off the Kubernetes Zookeeper and Kafka Helm Charts available at:
  https://github.com/kubernetes/charts/tree/master/incubator/zookeeper and
  https://github.com/kubernetes/charts/tree/master/incubator/kafka.
metadata:
  name: kafka-sasl
  annotations:
    description: |
      This template sets up an Kafka cluster in your project with a SASL_SSL endpoint enabled.
    openshift.io/display-name: Kafka cluster with SASL support
    template.openshift.io/documentation-url: https://github.com/nuxeo/nuxeo-openshift
    template.openshift.io/long-description: |-
      This template sets up an Kafka cluster in your project.
    template.openshift.io/provider-display-name: Nuxeo
    template.openshift.io/support-url: https://answers.nuxeo.com/
    iconClass: icon-java
    tags: java, nuxeo
parameters:
  - description: The name of the backings stack.
    displayName: The name of the backings stack.
    name: NUXEO_BACKINGS_NAME
    required: true
    value: "nuxeo-backings"
  - description: The number of ZooKeeper servers. This should always be (1,3,5, or 7)
    displayName: The number of ZooKeeper servers. This should always be (1,3,5, or 7)
    name: ZOOKEEPER_SERVER_COUNT
    required: true
    value: "3"
  - description: The maximum number of servers that may be unavailable during eviction. This should always be one.
    displayName: The maximum number of servers that may be unavailable during eviction. This should always be one.
    name: ZOOKEEPER_MAX_UNAVAILABLE
    required: true
    value: "30%"
  - description: The amount of CPU to request for Zookeeper
    displayName: The amount of CPU to request for Zookeeper
    name: ZOOKEEPER_REQUESTS_CPU
    required: true
    value: "500m"
  - description: The amount of memory to request for Zookeeper
    displayName: The amount of memory to request for Zookeeper
    name: ZOOKEEPER_REQUESTS_MEMORY
    required: true
    value: 1024Mi
  - description: The CPU limit for Zookeeper
    displayName: The CPU limit for Zookeeper
    name: ZOOKEEPER_LIMITS_CPU
    required: true
    value: "1"
  - description: The memory limit for Zookeeper
    displayName: The memory limit for Zookeeper
    name: ZOOKEEPER_LIMITS_MEMORY
    required: true
    value: 4096Mi
  - description: Zookeeper heap size
    displayName: Zookeeper heap size
    name: ZOOKEEPER_HEAP_SIZE
    required: true
    value: 512m
  - description: Zookeeper tick time
    displayName: Zookeeper tick time
    name: ZOOKEEPER_TICK_TIME
    required: true
    value: "2000"
  - description: Zookeeper init limit
    displayName: Zookeeper init limit
    name: ZOOKEEPER_INIT_LIMIT
    required: true
    value: "10"
  - description: Zookeeper sync limit
    displayName: Zookeeper sync limit
    name: ZOOKEEPER_SYNC_LIMIT
    required: true
    value: "5"
  - description: Zookeeper maximum client connections
    displayName: Zookeeper maximum client connections
    name: ZOOKEEPER_MAXIMUM_CLIENT_CONNECTIONS
    required: true
    value: "60"
  - description: Zookeeper snap retain count
    displayName: Zookeeper snap retain count
    name: ZOOKEEPER_SNAP_RETAIN_COUNT
    required: true
    value: "3"
  - description: Zookeeper purge interval
    displayName: Zookeeper purge interval
    name: ZOOKEEPER_PURGE_INTERVAL
    required: true
    value: "1"
  - description: Zookeeper log level
    displayName: Zookeeper log level
    name: ZOOKEEPER_LOG_LEVEL
    required: true
    value: INFO
  - description: Zookeeper client port
    displayName: Zookeeper client port
    name: ZOOKEEPER_CLIENT_PORT
    required: true
    value: "2181"
  - description: Zookeeper server port
    displayName: Zookeeper server port
    name: ZOOKEEPER_SERVER_PORT
    required: true
    value: "2888"
  - description: Zookeeper leader election port
    displayName: Zookeeper leader election port
    name: ZOOKEEPER_LEADER_ELECTION_PORT
    required: true
    value: "3888"
  - description: Number of seconds after the container has started before healthcheck probes are initiated.
    displayName: Zookeeper healthcheck initial delay
    name: ZOOKEEPER_HEALTHCHECK_DELAY
    value: "15"
  - description: Number of seconds after which the probe times out.
    displayName: Zookeeper healthcheck timeout
    name: ZOOKEEPER_HEALTHCHECK_TIMEOUT
    value: "5"
  - description: Zookeeper volume storage class
    displayName: Zookeeper volume storage class
    name: ZOOKEEPER_VOLUME_STORAGE_CLASS_NAME
    value: "aws-fast"
  - description: Volume space available for Zookeeper data, e.g. 512Mi, 2Gi.
    displayName: Zookeeper Volume Capacity
    name: ZOOKEEPER_VOLUME_CAPACITY
    required: true
    value: 1Gi
  - description: Zookeeper image name
    displayName: Zookeeper image Name
    name: ZOOKEEPER_IMAGE_NAME
    value: confluentinc/cp-zookeeper
  - description: Zookeeper image tag
    displayName: Zookeeper image tag
    name: ZOOKEEPER_IMAGE_TAG
    value: 4.0.0-3
  - description: Number of Kafka cluster servers which will be deployed
    displayName: Number of Kafka cluster servers
    name: KAFKA_SERVER_COUNT
    required: true
    value: "3"
  - description: The maximum number of servers that may be unavailable during eviction. This should always be one.
    displayName: The maximum number of servers that may be unavailable during eviction. This should always be one.
    name: KAFKA_MAX_UNAVAILABLE
    required: true
    value: "30%"
  - description: The amount of CPU to request for Kafka
    displayName: The amount of CPU to request for Kafka
    name: KAFKA_REQUESTS_CPU
    required: true
    value: "500m"
  - description: The amount of memory to request for Kafka
    displayName: The amount of memory to request for Kafka
    name: KAFKA_REQUESTS_MEMORY
    required: true
    value: 512Mi
  - description: The CPU limit for Kafka
    displayName: The CPU limit for Kafka
    name: KAFKA_LIMITS_CPU
    required: true
    value: "4"
  - description: The memory limit for Kafka
    displayName: The memory limit for Kafka
    name: KAFKA_LIMITS_MEMORY
    required: true
    value: 12Gi
  - description: Kafka heap size
    displayName: Kafka heap size
    name: KAFKA_HEAP_SIZE
    required: true
    value: 512m
  - description: Number of seconds after the container has started before healthcheck probes are initiated.
    displayName: Kafka healthcheck initial delay
    name: KAFKA_HEALTHCHECK_DELAY
    value: "15"
  - description: Number of seconds after which the probe times out.
    displayName: Kafka healthcheck timeout
    name: KAFKA_HEALTHCHECK_TIMEOUT
    value: "5"
  - description: Kafka volume storage class
    displayName: Kafka volume storage class
    name: KAFKA_VOLUME_STORAGE_CLASS_NAME
    value: "aws-fast"
  - description: Volume space available for Kafka data, e.g. 512Mi, 2Gi.
    displayName: Kafka Volume Capacity
    name: KAFKA_VOLUME_CAPACITY
    required: true
    value: 1Gi
  - description: Termination grace period in seconds for Kafka
    displayName: Kafka Termination Grace Period in seconds
    name: KAFKA_TERMINATION_GRACE_PERIOD
    required: true
    value: "300"
  - description: Kafka image name
    displayName: Kafka image Name
    name: KAFKA_IMAGE_NAME
    value: confluentinc/cp-kafka
  - description: Kafka image tag
    displayName: Kafka image tag
    name: KAFKA_IMAGE_TAG
    value: 4.0.0-3
  - description: Default replication factor for newly created topics
    displayName: Default replication factor
    name: KAFKA_DEFAULT_REPLICATION_FACTOR
    value: "1"
  - description: Replication factor for offsets topic
    displayName: Offsets replication factor
    name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
    value: "3"
  - description: Replication factor for transactions state log topic
    displayName: Transaction state replication factor
    name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
    value: "3"
  - description: Kafka offsets retention minutes
    displayName: Kafka offsets retention minutes
    name: KAFKA_OFFSETS_RETENTION_MINUTES
    value: "20160"  

objects:

- kind: PodDisruptionBudget
  metadata:
    name: ${NUXEO_BACKINGS_NAME}-zookeeper
    labels:    
      app: ${NUXEO_BACKINGS_NAME}
      component: zookeeper
  apiVersion: policy/v1beta1
  spec:
    selector:
      matchLabels:
        app: ${NUXEO_BACKINGS_NAME}
        component: zookeeper
    maxUnavailable: "${ZOOKEEPER_MAX_UNAVAILABLE}"

- apiVersion: v1
  kind: Service
  metadata:
    name: ${NUXEO_BACKINGS_NAME}-zookeeper
    labels:
      app: ${NUXEO_BACKINGS_NAME}
      component: zookeeper
  spec:
    ports:
    - port: ${ZOOKEEPER_CLIENT_PORT}
      name: client
    - port: ${ZOOKEEPER_SERVER_PORT}
      name: server
    - port: ${ZOOKEEPER_LEADER_ELECTION_PORT}
      name: leader-election
    clusterIP: None
    selector:
      app: ${NUXEO_BACKINGS_NAME}
      component: zookeeper

- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: ${NUXEO_BACKINGS_NAME}-zookeeper
    labels:
      app: ${NUXEO_BACKINGS_NAME}
      component: zookeeper
  spec:
    serviceName: ${NUXEO_BACKINGS_NAME}-zookeeper
    replicas: ${ZOOKEEPER_SERVER_COUNT}
    podManagementPolicy: Parallel
    updateStrategy:
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: ${NUXEO_BACKINGS_NAME}
          component: zookeeper
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: "app"
                    operator: In
                    values:
                    - "${NUXEO_BACKINGS_NAME}"
                  - key: "component"
                    operator: In
                    values:
                    - "zookeeper"
                topologyKey: "kubernetes.io/hostname"
        containers:
        - name: zookeeper-server
          image: ${ZOOKEEPER_IMAGE_NAME}:${ZOOKEEPER_IMAGE_TAG}
          resources:
            requests:
              cpu: "${ZOOKEEPER_REQUESTS_CPU}"
              memory: "${ZOOKEEPER_REQUESTS_MEMORY}"
            limits:
              cpu: "${ZOOKEEPER_LIMITS_CPU}"
              memory: "${ZOOKEEPER_LIMITS_MEMORY}"
          ports:
          - containerPort: ${ZOOKEEPER_CLIENT_PORT}
            name: client
          - containerPort: ${ZOOKEEPER_SERVER_PORT}
            name: server
          - containerPort: ${ZOOKEEPER_LEADER_ELECTION_PORT}
            name: leader-election
          env:
          - name : ZOOKEEPER_SERVER_COUNT
            value: ${ZOOKEEPER_SERVER_COUNT}
          - name : ZOOKEEPER_HEAP_SIZE
            value: ${ZOOKEEPER_HEAP_SIZE}
          - name : ZOOKEEPER_TICK_TIME
            value: ${ZOOKEEPER_TICK_TIME}
          - name : ZOOKEEPER_INIT_LIMIT
            value: ${ZOOKEEPER_INIT_LIMIT}
          - name : ZOOKEEPER_SYNC_LIMIT
            value: ${ZOOKEEPER_SYNC_LIMIT}
          - name : ZOOKEEPER_MAX_CLIENT_CNXNS
            value: ${ZOOKEEPER_MAXIMUM_CLIENT_CONNECTIONS}
          - name : ZOOKEEPER_SNAP_RETAIN_COUNT
            value: ${ZOOKEEPER_SNAP_RETAIN_COUNT}
          - name : ZOOKEEPER_PURGE_INTERVAL
            value: ${ZOOKEEPER_PURGE_INTERVAL}
          - name : ZOOKEEPER_LOG_LEVEL
            value: ${ZOOKEEPER_LOG_LEVEL}
          - name : ZOOKEEPER_CLIENT_PORT
            value: ${ZOOKEEPER_CLIENT_PORT}
          - name : ZOOKEEPER_SERVER_PORT
            value: ${ZOOKEEPER_SERVER_PORT}
          - name : ZOOKEEPER_ELECTION_PORT
            value: ${ZOOKEEPER_LEADER_ELECTION_PORT}
          command:
          - /bin/bash
          - -exc
          - |
            export ZOOKEEPER_SERVER_ID=$((${HOSTNAME##*-}+1)) && \
            export ZOOKEEPER_SERVERS=$(DOMAIN=`hostname -d`; \
                for ((i=0; i<$ZOOKEEPER_SERVER_COUNT; i++)); do \
                    echo -n "${NUXEO_BACKINGS_NAME}-zookeeper-$i.$DOMAIN:$ZOOKEEPER_SERVER_PORT:$ZOOKEEPER_ELECTION_PORT;"; \
                done| sed 's/;$//') && \
            /etc/confluent/docker/run
          readinessProbe:
            exec:
              command:
              - sh
              - -c
              - 'echo "ruok" | nc -w 2 -q 2 localhost ${ZOOKEEPER_CLIENT_PORT} | grep imok'
            initialDelaySeconds: ${ZOOKEEPER_HEALTHCHECK_DELAY}
            timeoutSeconds: ${ZOOKEEPER_HEALTHCHECK_TIMEOUT}
          livenessProbe:
            exec:
              command:
              - sh
              - -c
              - 'echo "ruok" | nc -w 2 -q 2 localhost ${ZOOKEEPER_CLIENT_PORT} | grep imok'
            initialDelaySeconds: ${ZOOKEEPER_HEALTHCHECK_DELAY}
            timeoutSeconds: ${ZOOKEEPER_HEALTHCHECK_TIMEOUT}
          volumeMounts:
          - name: datadir
            mountPath: /opt/zookeeper/data
    volumeClaimTemplates:
    - metadata:
        name: datadir
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: ${ZOOKEEPER_VOLUME_CAPACITY}
        storageClassName: "${ZOOKEEPER_VOLUME_STORAGE_CLASS_NAME}"


- kind: PodDisruptionBudget
  metadata:
    name: ${NUXEO_BACKINGS_NAME}-kafka
    labels:
      app: ${NUXEO_BACKINGS_NAME}
      component: kafka
  apiVersion: policy/v1beta1
  spec:
    selector:
      matchLabels:
        app: ${NUXEO_BACKINGS_NAME}
        component: kafka
    maxUnavailable: "${KAFKA_MAX_UNAVAILABLE}"

# Source: kafka/templates/service.yaml
- apiVersion: v1
  kind: Service
  metadata:
    name: ${NUXEO_BACKINGS_NAME}-kafka
    labels:
      app: ${NUXEO_BACKINGS_NAME}
      component: kafka
    annotations:
      service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  spec:
    ports:
    - port: 9092
      name: broker
    clusterIP: None
    selector:
      app: ${NUXEO_BACKINGS_NAME}
      component: kafka

# Source: kafka/templates/statefulset.yaml
- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: ${NUXEO_BACKINGS_NAME}-kafka
    labels:
      app: ${NUXEO_BACKINGS_NAME}
      component: kafka
  spec:
    serviceName: ${NUXEO_BACKINGS_NAME}-kafka
    replicas: ${KAFKA_SERVER_COUNT}
    podManagementPolicy: Parallel
    updateStrategy:
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: ${NUXEO_BACKINGS_NAME}
          component: kafka
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: "app"
                    operator: In
                    values:
                    - "${NUXEO_BACKINGS_NAME}"
                  - key: "component"
                    operator: In
                    values:
                    - "kafka"
                topologyKey: "kubernetes.io/hostname"
        terminationGracePeriodSeconds: ${KAFKA_TERMINATION_GRACE_PERIOD}
        containers:
        - name: kafka
          image: ${KAFKA_IMAGE_NAME}:${KAFKA_IMAGE_TAG}
          resources:
            requests:
              cpu: "${KAFKA_REQUESTS_CPU}"
              memory: "${KAFKA_REQUESTS_MEMORY}"
            limits:
              cpu: "${KAFKA_LIMITS_CPU}"
              memory: "${KAFKA_LIMITS_MEMORY}"
          livenessProbe:
            tcpSocket:
              port: 9092
            initialDelaySeconds: ${KAFKA_HEALTHCHECK_DELAY}
            timeoutSeconds: ${KAFKA_HEALTHCHECK_TIMEOUT}
          readinessProbe:
            exec:
              command:
              - /bin/bash
              - -exc
              - |
                export KAFKA_ZOOKEEPER_CONNECT=$(DOMAIN=`hostname -d`; \
                    for ((i=0; i<$ZOOKEEPER_SERVER_COUNT; i++)); do \
                        echo -n "${NUXEO_BACKINGS_NAME}-zookeeper-$i.$DOMAIN:$ZOOKEEPER_CLIENT_PORT,"; \
                    done| sed 's/,$//'| sed 's/kafka/zookeeper/g') && \
                (kafka-topics --zookeeper ${KAFKA_ZOOKEEPER_CONNECT} --list)
            initialDelaySeconds: ${KAFKA_HEALTHCHECK_DELAY}
            timeoutSeconds: ${KAFKA_HEALTHCHECK_TIMEOUT}
          ports:
          - containerPort: 9092
            name: kafka
          env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: ZOOKEEPER_SERVER_COUNT
            value: ${ZOOKEEPER_SERVER_COUNT}
          - name: ZOOKEEPER_CLIENT_PORT
            value: ${ZOOKEEPER_CLIENT_PORT}
          - name: KAFKA_HEAP_SIZE
            value: ${KAFKA_HEAP_SIZE}
          - name: KAFKA_OFFSETS_RETENTION_MINUTES
            value: ${KAFKA_OFFSETS_RETENTION_MINUTES}    
          - name: KAFKA_DEFAULT_REPLICATION_FACTOR
            value: "${KAFKA_DEFAULT_REPLICATION_FACTOR}"
          - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
            value: "${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}"
          - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
            value: "${KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}"
          
          - name: KAFKA_SSL_KEYSTORE_CREDENTIALS
            value: "keystore_credential"
          - name: KAFKA_SSL_KEY_CREDENTIALS
            value: "key_credential"
          - name: KAFKA_SSL_TRUSTSTORE_FILENAME
            value: "kafka.truststore.jks"
          - name: KAFKA_SSL_TRUSTSTORE_CREDENTIALS
            value: "truststore_credential"
          - name: KAFKA_OPTS
            value: -Djava.security.auth.login.config=/etc/kafka/secrets/jaas.conf
          - name: ZOOKEEPER_SASL_ENABLED
            value: "false"
          - name: KAFKA_SASL_ENABLED_MECHANISMS
            value: PLAIN
          - name: KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL
            value: PLAIN
          # This is required because the Downward API does not yet support identification of
          # pod numbering in statefulsets. Thus, we are required to specify a command which
          # allows us to extract the pod ID for usage as the Kafka Broker ID.
          # See: https://github.com/kubernetes/kubernetes/issues/31218
          command:
          - /bin/bash
          - -exc

          - |
            export KAFKA_ZOOKEEPER_CONNECT=$(DOMAIN=`hostname -d`; \
                for ((i=0; i<$ZOOKEEPER_SERVER_COUNT; i++)); do \
                    echo -n "${NUXEO_BACKINGS_NAME}-zookeeper-$i.$DOMAIN:$ZOOKEEPER_CLIENT_PORT,"; \
                done| sed 's/,$//'| sed 's/kafka/zookeeper/g') && \
            export KAFKA_HEAP_OPTS="-Xmx${KAFKA_HEAP_SIZE} -Xms${KAFKA_HEAP_SIZE}" && \
            export KAFKA_BROKER_ID=${HOSTNAME##*-} && \
            export KAFKA_SSL_KEYSTORE_FILENAME=kafka.broker${KAFKA_BROKER_ID}.keystore.jks
            export NODEPORT=$(expr 31092 + $KAFKA_BROKER_ID) && \
            export KAFKA_LISTENERS=PLAINTEXT://${POD_IP}:9092,SASL_SSL://${POD_IP}:9093 && \            
            export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${POD_IP}:9092,SASL_SSL://oso-dev-app-node0${KAFKA_BROKER_ID+1}.dev.nuxeo.io:${NODEPORT} && \
            /etc/confluent/docker/run
          volumeMounts:
          - name: datadir
            mountPath: /opt/kafka/data
          - name: certs
            mountPath: /etc/kafka/secrets
        volumes:
        - name: certs
          secret:
            secretName: ${NUXEO_BACKINGS_NAME}-kafka-keystore
    volumeClaimTemplates:
    - metadata:
        name: datadir
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: ${KAFKA_VOLUME_CAPACITY}
        storageClassName: "${KAFKA_VOLUME_STORAGE_CLASS_NAME}"
