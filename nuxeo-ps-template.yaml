apiVersion: v1
kind: Template
message: |-
  The following backing services for Nuxeo have been created in your project:

    * a MongoDB instance
    * an Elasticsearch simple node    
    * a dev deployment
    * a uat deployment
    * a pipeline build

  Please add a Github webhook to https://openshift.dev.nuxeo.io/oapi/v1/namespaces/<<NAMESPACE>>/buildconfigs/${APPLICATION_NAME}-pipeline/webhooks/${GITHUB_WEBHOOK_SECRET}/github
metadata:  
  name: nuxeo-ps-pipeline
  namespace: openshift
  annotations:
    description: |
      This template setup a basic development environment for professional services.
    openshift.io/display-name: Nuxeo PS dev environment (no cluster)
    template.openshift.io/documentation-url: https://github.com/nuxeo/nuxeo-openshift
    template.openshift.io/long-description: |-
      This template setup a basic development environment for professional services.
    template.openshift.io/provider-display-name: Nuxeo
    template.openshift.io/support-url: https://answers.nuxeo.com/
    iconClass: icon-java
    tags: java, nuxeo
parameters:
  - description: The name for the application.
    name: APPLICATION_NAME
    value: nuxeo
    required: true
  - description: The URL of the repository with your Nuxeo project to build
    name: SOURCE_REPOSITORY_URL
    value: https://github.com/nuxeo/nuxeo-customer-project-sample
    required: true
  - description: The reference to checkout.
    name: SOURCE_REPOSITORY_REF
    value: "master"
    required: true
  - description: The Nuxeo version to use. Use the version of the image (latest, 9.2, 8.10...)
    name: NUXEO_VERSION
    value: "9.3"
    required: true
  - description: Github Webhook secret (leave empty and it will be generated)
    name: GITHUB_WEBHOOK_SECRET
    required: true
    from: "[a-zA-Z0-9]{12}"
    generate: "expression"            
  - description: A Nuxeo Connect userId passed to the build of the image.
    name: NUXEO_CONNECT_USERNAME
    required: false
  - description: The password of the Nuxeo Connect account passed to the build of the image.
    name: NUXEO_CONNECT_PASSWORD
    required: false
  - description: The name of the studio project passed to the build of the image.
    name: NUXEO_STUDIO_PROJECT
    required: false
  - description: The version of the studio project passed the build of the image
    name: NUXEO_STUDIO_VERSION
    required: false
    value: 0.0.0-SNAPSHOT
  - description: Size of persistent storage for Binaries.
    name: VOLUME_BINARIES_CAPACITY
    value: 5Gi
    required: true
  - description: Size of persistent storage for MongoDB.
    name: VOLUME_MONGODB_CAPACITY
    value: 5Gi
    required: true
  - description: Size of persistent storage for Elasticsearch.
    name: VOLUME_ELASTICSEARCH_CAPACITY
    value: 5Gi
    required: true
  - description: Elasticsearch cluster name
    name: ELASTICSEARCH_CLUSTER_NAME
    value: nuxeo
    required: true
  - description: Elasticsearch Memory
    name: ELASTICSEARCH_CLUSTER_MEMORY
    value: 256m
    required: true
  - description: Domain suffix for routes
    name: DOMAIN_SUFFIX
    value: apps.dev.nuxeo.io
    required: true
  - description: Storage class for persistence volumes
    name: STORAGE_CLASS
    value: gp2
    required: true
  
objects:



############################################################################################################
# Backing services (ES and Mongo)
############################################################################################################

- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: ${APPLICATION_NAME}-elasticsearch-config
    labels:
      app: ${APPLICATION_NAME}-storage
      component: elasticsearch
      role: config
  data:
    elasticsearch.yml: |-
      cluster.name: ${ELASTICSEARCH_CLUSTER_NAME}      
      
      node.data: ${NODE_DATA:true}
      node.master: ${NODE_MASTER:true}
      node.ingest: ${NODE_INGEST:true}
      node.name: ${HOSTNAME}

      network.host: 0.0.0.0

      # see https://github.com/kubernetes/kubernetes/issues/3595
      bootstrap.memory_lock: ${BOOTSTRAP_MEMORY_LOCK:false}

      discovery:
        zen:
          minimum_master_nodes: ${MINIMUM_MASTER_NODES}

      # see https://www.elastic.co/guide/en/x-pack/current/xpack-settings.html
      xpack.ml.enabled: ${XPACK_ML_ENABLED:false}
      xpack.monitoring.enabled: ${XPACK_MONITORING_ENABLED:false}
      xpack.security.enabled: ${XPACK_SECURITY_ENABLED:false}
      xpack.watcher.enabled: ${XPACK_WATCHER_ENABLED:false}

      # see https://github.com/elastic/elasticsearch-definitive-guide/pull/679
      processors: ${PROCESSORS:}

      # avoid split-brain w/ a minimum consensus of two masters plus a data node
      gateway.expected_master_nodes: ${EXPECTED_MASTER_NODES:2}
      gateway.expected_data_nodes: ${EXPECTED_DATA_NODES:1}
      gateway.recover_after_time: ${RECOVER_AFTER_TIME:5m}
      gateway.recover_after_master_nodes: ${RECOVER_AFTER_MASTER_NODES:2}
      gateway.recover_after_data_nodes: ${RECOVER_AFTER_DATA_NODES:1}
    logging.yml: |-
      # you can override this using by setting a system property, for example -Des.logger.level=DEBUG
      es.logger.level: INFO
      rootLogger: ${es.logger.level}, console
      logger:
        # log action execution errors for easier debugging
        action: DEBUG
        # reduce the logging for aws, too much is logged under the default INFO
        com.amazonaws: WARN

      appender:
        console:
          type: console
          layout:
            type: consolePattern
            conversionPattern: "[%d{ISO8601}][%-5p][%-25c] %m%n"
    pre-stop-hook.sh: |-
      #!/bin/bash
      set -e

      SERVICE_ACCOUNT_PATH=/var/run/secrets/kubernetes.io/serviceaccount
      KUBE_TOKEN=$(<${SERVICE_ACCOUNT_PATH}/token)
      KUBE_NAMESPACE=$(<${SERVICE_ACCOUNT_PATH}/namespace)

      STATEFULSET_NAME=$(echo "${HOSTNAME}" | sed 's/-[0-9]*$//g')
      INSTANCE_ID=$(echo "${HOSTNAME}" | grep -o '[0-9]*$')

      echo "Prepare stopping of Pet ${KUBE_NAMESPACE}/${HOSTNAME} of StatefulSet ${KUBE_NAMESPACE}/${STATEFULSET_NAME} instance_id ${INSTANCE_ID}"

      INSTANCES_DESIRED=$(curl -s \
        --cacert ${SERVICE_ACCOUNT_PATH}/ca.crt \
        -H "Authorization: Bearer $KUBE_TOKEN" \
        "https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_PORT_443_TCP_PORT}/apis/apps/v1beta1/namespaces/${KUBE_NAMESPACE}/statefulsets/${STATEFULSET_NAME}/status" | jq -r '.spec.replicas')

      echo "Desired instance count is ${INSTANCES_DESIRED}"

      if [ "${INSTANCE_ID}" -lt "${INSTANCES_DESIRED}" ]; then
        echo "No data migration needed"
        exit 0
      fi

      echo "Prepare to migrate data of the node"

      NODE_STATS=$(curl -s -XGET 'http://localhost:9200/_nodes/stats')
      NODE_IP=$(echo "${NODE_STATS}" | jq -r ".nodes[] | select(.name==\"${HOSTNAME}\") | .host")

      echo "Move all data from node ${NODE_IP}"

      curl -s -XPUT localhost:9200/_cluster/settings -d "{
        \"transient\" :{
            \"cluster.routing.allocation.exclude._ip\" : \"${NODE_IP}\"
        }
      }"
      echo

      echo "Wait for node to become empty"
      DOC_COUNT=$(echo "${NODE_STATS}" | jq ".nodes[] | select(.name==\"${HOSTNAME}\") | .indices.docs.count")
      while [ "${DOC_COUNT}" -gt 0 ]; do
        NODE_STATS=$(curl -s -XGET 'http://localhost:9200/_nodes/stats')
        DOC_COUNT=$(echo "${NODE_STATS}" | jq -r ".nodes[] | select(.name==\"${HOSTNAME}\") | .indices.docs.count")
        echo "Node contains ${DOC_COUNT} documents"
        sleep 1
      done

      echo "Wait for node shards to become empty"
      SHARD_STATS=$(curl -s -XGET 'http://localhost:9200/_cat/shards?format=json')
      SHARD_COUNT=$(echo "${SHARD_STATS}" | jq "[.[] | select(.node==\"${HOSTNAME}\")] | length")
      while [ "${SHARD_COUNT}" -gt 0 ]; do
        SHARD_STATS=$(curl -s -XGET 'http://localhost:9200/_cat/shards?format=json')
        SHARD_COUNT=$(echo "${SHARD_STATS}" | jq "[.[] | select(.node==\"${HOSTNAME}\")] | length")
        echo "Node contains ${SHARD_COUNT} shards"
        sleep 1
      done

      echo "Node clear to shutdown"




- apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      app: ${APPLICATION_NAME}-storage
    name: elasticsearch


# Source: elasticsearch/templates/client-svc.yaml
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: ${APPLICATION_NAME}-storage
      component: elasticsearch
      role: client
    name: ${APPLICATION_NAME}-elasticsearch
  spec:
    ports:
      - name: client
        port: 9200
        targetPort: client
    selector:
      app: ${APPLICATION_NAME}-storage
      component: elasticsearch
    type: ClusterIP




  # Source: elasticsearch/templates/data-statefulset.yaml
- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    labels:
      app: ${APPLICATION_NAME}-storage
      component: elasticsearch
      role: data
    name: ${APPLICATION_NAME}-elasticsearch
  spec:
    serviceName: ${APPLICATION_NAME}-elasticsearch
    replicas: 1
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}-storage
          component: elasticsearch
      spec:
        serviceAccountName: elasticsearch
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    app: ${APPLICATION_NAME}-storage                  
                    component: elasticsearch
                    role: data
        initContainers:
        # see https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
        # and https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html#mlockall
        - name: "sysctl"
          image: "busybox"
          imagePullPolicy: "Always"
          command: ["sysctl", "-w", "vm.max_map_count=262144"]
          securityContext:
            privileged: true
        - name: "chown"
          image: "docker.elastic.co/elasticsearch/elasticsearch:5.6.5"
          imagePullPolicy: "IfNotPresent"
          command:
          - /bin/bash
          - -c
          - chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data &&
            chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/logs
          securityContext:
            runAsUser: 0
          volumeMounts:
          - mountPath: /usr/share/elasticsearch/data
            name: data
        containers:
        - name: elasticsearch
          env:
          - name: KUBERNETES_MASTER
            value: kubernetes.default.svc.cluster.local
          - name: KUBERNETES_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: NODE_MASTER
            value: "true"
          - name: PROCESSORS
            valueFrom:
              resourceFieldRef:
                resource: limits.cpu
          - name: EXPECTED_MASTER_NODES
            value: "1"
          - name: RECOVER_AFTER_MASTER_NODES
            value: "1"
          - name: ES_JAVA_OPTS
            value: "-Djava.net.preferIPv4Stack=true -Xms${ELASTICSEARCH_CLUSTER_MEMORY} -Xmx${ELASTICSEARCH_CLUSTER_MEMORY}"
          - name: MINIMUM_MASTER_NODES
            value: "1"
          image: "docker.elastic.co/elasticsearch/elasticsearch:5.6.5"
          imagePullPolicy: "IfNotPresent"
          ports:
          - containerPort: 9200
            name: client
          resources:
              limits:
                cpu: "1"
              requests:
                cpu: 25m
                memory: ${ELASTICSEARCH_CLUSTER_MEMORY}
              
          readinessProbe:
            httpGet:
              path: /_cluster/health?wait_for_status=yellow
              port: 9200
            initialDelaySeconds: 5
          livenessProbe:
            httpGet:
              path: /_cluster/health?wait_for_status=yellow
              port: 9200
            initialDelaySeconds: 90
          volumeMounts:
          - mountPath: /usr/share/elasticsearch/data
            name: data
          - mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
            name: config
            subPath: elasticsearch.yml
          - mountPath: /usr/share/elasticsearch/config/logging.yml
            name: config
            subPath: logging.yml
          - name: config
            mountPath: /pre-stop-hook.sh
            subPath: pre-stop-hook.sh
          lifecycle:
            preStop:
              exec:
                command: ["/bin/bash","/pre-stop-hook.sh"]
        terminationGracePeriodSeconds: 3600
        volumes:
        - name: config
          configMap:
            name: ${APPLICATION_NAME}-elasticsearch-config
    volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app: ${APPLICATION_NAME}   
        annotations:
          volume.beta.kubernetes.io/storage-class: ${STORAGE_CLASS}
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: ${VOLUME_ELASTICSEARCH_CAPACITY}


    

- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-mongo
    labels:
      app: ${APPLICATION_NAME}-storage
      component: mongo
  spec:
    ports:
    - port: 27017
      targetPort: 27017
    clusterIP: None
    selector:
      app: ${APPLICATION_NAME}-storage
      component: mongo

- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: ${APPLICATION_NAME}-mongo
  spec:
    serviceName: ${APPLICATION_NAME}-mongo
    replicas: 1
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}-storage
          component: mongo          
      spec:
        terminationGracePeriodSeconds: 10
        containers:
          - name: mongo
            image: mongo:3.4
            command:
              - mongod
              - "--smallfiles"
              - "--noprealloc"
            ports:
              - containerPort: 27017
            volumeMounts:
              - name: data
                mountPath: /data/db

    volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app: ${APPLICATION_NAME}-storage
        annotations:
          volume.beta.kubernetes.io/storage-class: ${STORAGE_CLASS}
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            # TODO: add parameter
            storage: ${VOLUME_MONGODB_CAPACITY}

############################################################################################################
# Commons
############################################################################################################


- apiVersion: v1
  kind: Secret
  metadata:
    name: ${APPLICATION_NAME}-connect
    labels:
      app: ${APPLICATION_NAME}
  stringData:
    connect.properties: |-
      NUXEO_STUDIO_PROJECT=${NUXEO_STUDIO_PROJECT}
      NUXEO_STUDIO_PROJECT_VERSION=${NUXEO_STUDIO_VERSION}
      NUXEO_CONNECT_USERNAME=${NUXEO_CONNECT_USERNAME}
      NUXEO_CONNECT_PASSWORD=${NUXEO_CONNECT_PASSWORD}


- apiVersion: v1
  kind: ImageStream
  metadata:      
    creationTimestamp: null
    name: ${APPLICATION_NAME}-nuxeo
    labels:
      app: ${APPLICATION_NAME}
  spec:
    dockerImageRepository: nuxeo


############################################################################################################
# DEV Deployment
############################################################################################################


- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: ${APPLICATION_NAME}-dev-conf   
    labels:
      app: ${APPLICATION_NAME}-dev
      role: config
      stage: dev
  data:
    nuxeo.conf: |
      # Additional nuxeo.conf parameters      
    init.sh: |
      #!/bin/sh

      ## Need to use nss_wrapper in order to make LibreOffice conversion works
      ## cf https://docs.openshift.com/enterprise/3.2/creating_images/guidelines.html
      export USER_ID=$(id -u)
      export GROUP_ID=$(id -g)

      cat > /tmp/passwd <<EOT
      root:x:0:0:root:/root:/bin/bash
      nuxeo:x:${USER_ID}:${GROUP_ID}:Nuxeo server:/tmp:/bin/bash
      EOT

      export LD_PRELOAD=/usr/lib/libnss_wrapper.so
      export NSS_WRAPPER_PASSWD=/tmp/passwd
      export NSS_WRAPPER_GROUP=/etc/group

      if [ ! -f $NUXEO_DATA/instance.clid -a -f /opt/nuxeo/connect/connect.properties ]; then
        . /opt/nuxeo/connect/connect.properties
        if [ -n "$NUXEO_CONNECT_USERNAME" -a -n "$NUXEO_CONNECT_PASSWORD" -a -n "$NUXEO_STUDIO_PROJECT" ]; then  
          echo "---> Registering instance on connect"
          nuxeoctl register $NUXEO_CONNECT_USERNAME $NUXEO_STUDIO_PROJECT dev openshift $NUXEO_CONNECT_PASSWORD
        fi
      fi

- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    annotations:
      volume.beta.kubernetes.io/storage-class: ${STORAGE_CLASS}
    creationTimestamp: null
    name: ${APPLICATION_NAME}-dev-binaries
    labels:
      app: ${APPLICATION_NAME}-dev
      role: data
      stage: dev
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: ${VOLUME_BINARIES_CAPACITY}


- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    labels:
      app: ${APPLICATION_NAME}-dev
      stage: dev
      component: nuxeo
    name: ${APPLICATION_NAME}-dev-nuxeo
  spec:
    strategy:
      type: Rolling
      activeDeadlineSeconds: 21600
      resources: {}
      rollingParams:
        intervalSeconds: 1
        maxSurge: 25%
        maxUnavailable: 25%
        timeoutSeconds: 600
        updatePeriodSeconds: 1
    replicas: 1
    selector:
      app: ${APPLICATION_NAME}-dev
      component: nuxeo
      stage: dev
      deploymentconfig: ${APPLICATION_NAME}-dev-nuxeo
    
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: ${APPLICATION_NAME}-dev
          component: nuxeo
          stage: dev
          deploymentconfig: ${APPLICATION_NAME}-dev-nuxeo
      spec:
        containers:
        - image: ${APPLICATION_NAME}-nuxeo:latest
          imagePullPolicy: Always
          livenessProbe:
            httpGet:
              path: /nuxeo/runningstatus
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            timeoutSeconds: 5
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /nuxeo/runningstatus
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: ${APPLICATION_NAME}-appserver
          env:
          - name: NUXEO_TEMPLATES
            value: "default,mongodb,mongodb-audit"
          - name: NUXEO_CUSTOM_PARAM
            value: |
              nuxeo.mongodb.server=mongodb://${APPLICATION_NAME}-mongo-0.${APPLICATION_NAME}-mongo:27017
              nuxeo.mongodb.dbname=${APPLICATION_NAME}-dev
              elasticsearch.client=RestClient
              elasticsearch.httpReadOnly.baseUrl=http://${APPLICATION_NAME}-elasticsearch:9200
              elasticsearch.indexName=${APPLICATION_NAME}-dev
              mail.transport.host=aws-smtp-relay.common.svc
              mail.from=noreply@nuxeo.io               
              
          - name: NUXEO_PACKAGES
            value: nuxeo-web-ui
          - name: NUXEO_URL
            value: htts://${APPLICATION_NAME}-dev.${DOMAIN_SUFFIX}
          - name: NUXEO_ES_HOSTS
            value: ${APPLICATION_NAME}-elasticsearch:9200
          - name: NUXEO_ES_CLUSTERNAME
            value: ${ELASTICSEARCH_CLUSTER_NAME}
          - name: NUXEO_ES_REPLICAS
            value: "0"
          - name: NUXEO_BINARY_STORE
            value: /binaries
          
          ports:
          - containerPort: 8080
            protocol: TCP
          volumeMounts:
          - name: ${APPLICATION_NAME}-binaries
            mountPath: /binaries
          - name: nuxeoconf
            mountPath: /docker-entrypoint-initnuxeo.d
          - name: connect-secret
            mountPath: /opt/nuxeo/connect

          - name: nuxeodata
            mountPath: /var/lib/nuxeo/data
          - name: nuxeolog
            mountPath: /var/log/nuxeo
          - name: nuxeotmp
            mountPath: /opt/nuxeo/server/tmp
        volumes:
        - name: ${APPLICATION_NAME}-binaries
          persistentVolumeClaim:
            claimName: ${APPLICATION_NAME}-dev-binaries
        - name: nuxeoconf
          configMap:
            name: ${APPLICATION_NAME}-dev-conf  
        - name: connect-secret
          secret:
            secretName: ${APPLICATION_NAME}-connect
        - name: nuxeodata
          emptyDir: {}
        - name: nuxeolog
          emptyDir: {}
        - name: nuxeotmp
          emptyDir: {}
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        terminationGracePeriodSeconds: 30        
    test: false
    triggers:
    - type: ConfigChange
    - type: "ImageChange"
      imageChangeParams:
        automatic: false
        containerNames:
        - ${APPLICATION_NAME}-appserver
        from:
          kind: ImageStreamTag
          name: ${APPLICATION_NAME}-nuxeo:latest
    
- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-dev-nuxeo
    labels:
      app: ${APPLICATION_NAME}-dev
      component: nuxeo
      role: lb
  spec:
    clusterIP: None    
    selector:
      app: ${APPLICATION_NAME}-dev
      component: nuxeo
      stage: dev
    ports:
    - name: 8080-tcp
      port: 8080
      protocol: TCP

- apiVersion: v1
  kind: Route
  metadata:
    labels:
      app: ${APPLICATION_NAME}-dev
    name: ${APPLICATION_NAME}-dev-nuxeo-route  
  spec:
    host: ${APPLICATION_NAME}-dev.${DOMAIN_SUFFIX}
    tls:
      termination: edge
      insecureEdgeTerminationPolicy: Redirect
    to:
      kind: Service
      name: ${APPLICATION_NAME}-dev-nuxeo
    port:
      targetPort: 8080-tcp
    wildcardPolicy: None

############################################################################################################
# UAT Deployment
############################################################################################################


- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: ${APPLICATION_NAME}-uat-conf   
    labels:
      app: ${APPLICATION_NAME}-uat
      role: config
      stage: dev
  data:
    nuxeo.conf: |
      # Additional nuxeo.conf parameters      
    init.sh: |
      #!/bin/sh

      ## Need to use nss_wrapper in order to make LibreOffice conversion works
      ## cf https://docs.openshift.com/enterprise/3.2/creating_images/guidelines.html
      export USER_ID=$(id -u)
      export GROUP_ID=$(id -g)

      cat > /tmp/passwd <<EOT
      root:x:0:0:root:/root:/bin/bash
      nuxeo:x:${USER_ID}:${GROUP_ID}:Nuxeo server:/tmp:/bin/bash
      EOT

      export LD_PRELOAD=/usr/lib/libnss_wrapper.so
      export NSS_WRAPPER_PASSWD=/tmp/passwd
      export NSS_WRAPPER_GROUP=/etc/group

      if [ ! -f $NUXEO_DATA/instance.clid -a -f /opt/nuxeo/connect/connect.properties ]; then
        . /opt/nuxeo/connect/connect.properties
        if [ -n "$NUXEO_CONNECT_USERNAME" -a -n "$NUXEO_CONNECT_PASSWORD" -a -n "$NUXEO_STUDIO_PROJECT" ]; then  
          echo "---> Registering instance on connect"
          nuxeoctl register $NUXEO_CONNECT_USERNAME $NUXEO_STUDIO_PROJECT dev openshift $NUXEO_CONNECT_PASSWORD
        fi
      fi

- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    annotations:
      volume.beta.kubernetes.io/storage-class: ${STORAGE_CLASS}
    creationTimestamp: null
    name: ${APPLICATION_NAME}-uat-binaries
    labels:
      app: ${APPLICATION_NAME}-uat
      role: data
      stage: uat
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: ${VOLUME_BINARIES_CAPACITY}


- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    labels:
      app: ${APPLICATION_NAME}-uat
      stage: uat
      component: nuxeo
    name: ${APPLICATION_NAME}-uat-nuxeo
  spec:
    strategy:
      type: Rolling
      activeDeadlineSeconds: 21600
      resources: {}
      rollingParams:
        intervalSeconds: 1
        maxSurge: 25%
        maxUnavailable: 25%
        timeoutSeconds: 600
        updatePeriodSeconds: 1
    replicas: 1
    selector:
      app: ${APPLICATION_NAME}-uat
      component: nuxeo
      stage: uat
      deploymentconfig: ${APPLICATION_NAME}-uat-nuxeo
    
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: ${APPLICATION_NAME}-uat
          component: nuxeo
          stage: uat
          deploymentconfig: ${APPLICATION_NAME}-uat-nuxeo
      spec:
        containers:
        - image: ${APPLICATION_NAME}-nuxeo:latest
          imagePullPolicy: Always
          livenessProbe:
            httpGet:
              path: /nuxeo/runningstatus
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            timeoutSeconds: 5
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /nuxeo/runningstatus
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: ${APPLICATION_NAME}-appserver
          env:
          - name: NUXEO_TEMPLATES
            value: "default,mongodb,mongodb-audit"
          - name: NUXEO_CUSTOM_PARAM
            value: |
              nuxeo.mongodb.server=mongodb://${APPLICATION_NAME}-mongo-0.${APPLICATION_NAME}-mongo:27017
              nuxeo.mongodb.dbname=${APPLICATION_NAME}-uat
              elasticsearch.client=RestClient
              elasticsearch.httpReadOnly.baseUrl=http://${APPLICATION_NAME}-elasticsearch:9200
              elasticsearch.indexName=${APPLICATION_NAME}-uat
              mail.transport.host=aws-smtp-relay.common.svc
              mail.from=noreply@nuxeo.io               
              
          - name: NUXEO_PACKAGES
            value: nuxeo-web-ui
          - name: NUXEO_URL
            value: htts://${APPLICATION_NAME}-dev.${DOMAIN_SUFFIX}
          - name: NUXEO_ES_HOSTS
            value: ${APPLICATION_NAME}-elasticsearch:9200
          - name: NUXEO_ES_CLUSTERNAME
            value: ${ELASTICSEARCH_CLUSTER_NAME}
          - name: NUXEO_ES_REPLICAS
            value: "0"
          - name: NUXEO_BINARY_STORE
            value: /binaries
          
          ports:
          - containerPort: 8080
            protocol: TCP
          volumeMounts:
          - name: ${APPLICATION_NAME}-binaries
            mountPath: /binaries
          - name: nuxeoconf
            mountPath: /docker-entrypoint-initnuxeo.d
          - name: connect-secret
            mountPath: /opt/nuxeo/connect

          - name: nuxeodata
            mountPath: /var/lib/nuxeo/data
          - name: nuxeolog
            mountPath: /var/log/nuxeo
          - name: nuxeotmp
            mountPath: /opt/nuxeo/server/tmp
        volumes:
        - name: ${APPLICATION_NAME}-binaries
          persistentVolumeClaim:
            claimName: ${APPLICATION_NAME}-uat-binaries
        - name: nuxeoconf
          configMap:
            name: ${APPLICATION_NAME}-uat-conf  
        - name: connect-secret
          secret:
            secretName: ${APPLICATION_NAME}-connect
        - name: nuxeodata
          emptyDir: {}
        - name: nuxeolog
          emptyDir: {}
        - name: nuxeotmp
          emptyDir: {}
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        terminationGracePeriodSeconds: 30        
    test: false
    triggers:
    - type: ConfigChange
    - type: "ImageChange"
      imageChangeParams:
        automatic: false
        containerNames:
        - ${APPLICATION_NAME}-appserver
        from:
          kind: ImageStreamTag
          name: ${APPLICATION_NAME}-nuxeo:latest
    
- apiVersion: v1
  kind: Service
  metadata:
    name: ${APPLICATION_NAME}-uat-nuxeo
    labels:
      app: ${APPLICATION_NAME}-uat
      component: nuxeo
      role: lb
  spec:
    clusterIP: None
    selector:
      app: ${APPLICATION_NAME}-uat
      component: nuxeo
      stage: uat
    ports:
    - name: 8080-tcp
      port: 8080
      protocol: TCP

- apiVersion: v1
  kind: Route
  metadata:
    labels:
      app: ${APPLICATION_NAME}-uat
    name: ${APPLICATION_NAME}-uat-nuxeo-route  
  spec:
    # TODO: Add parameter
    host: ${APPLICATION_NAME}-uat.${DOMAIN_SUFFIX}
    tls:
      termination: edge
      insecureEdgeTerminationPolicy: Redirect    
    to:
      kind: Service
      name: ${APPLICATION_NAME}-uat-nuxeo
    port:
      targetPort: 8080-tcp
    wildcardPolicy: None



############################################################################################################
# Build pipeline
############################################################################################################


- apiVersion: v1
  kind: ImageStream
  metadata:          
    name: ${APPLICATION_NAME}-base-image
    labels:
      app: ${APPLICATION_NAME}
  spec: {}
  status:
    dockerImageRepository: ""    


- apiVersion: v1
  kind: BuildConfig
  metadata:
    labels:
      app: ${APPLICATION_NAME}
      component: build
    name: ${APPLICATION_NAME}-base-image-build
  spec:
    nodeSelector: null
    output:
      to:
        kind: ImageStreamTag
        name: '${APPLICATION_NAME}-base-image:latest'
    postCommit: {}
    resources: {}
    runPolicy: Serial
    source:
      dockerfile: |-
          FROM nuxeo:9.10
          USER root

          # Reinstall ImageMagick with the RSVG delegate
          RUN apt-get update && \
              apt-get remove -y imagemagick && \
              apt-get install -y --no-install-recommends librsvg2-bin && \
              apt-get install -y imagemagick && \
              apt-get install -y --no-install-recommends vim libnss-wrapper && \
              wget http://apt.nuxeo.org/pool/releases/ffmpeg-nuxeo_2.8.5-1_amd64.deb && \
              dpkg -i ffmpeg-nuxeo_2.8.5-1_amd64.deb && \
              rm -f ffmpeg-nuxeo_2.8.5-1_amd64.deb    
          USER 1000
      type: Dockerfile
    strategy:
      dockerStrategy: {}
      type: Docker



- apiVersion: v1
  kind: ImageStream
  metadata:          
    name: ${APPLICATION_NAME}-app-build
    labels:
      app: ${APPLICATION_NAME}
  spec: {}
  status:
    dockerImageRepository: ""    


- apiVersion: v1
  kind: BuildConfig
  metadata:
    creationTimestamp: null
    labels:
      app: ${APPLICATION_NAME}
      component: build
    name: ${APPLICATION_NAME}-app-build
  spec:
    source:
      git:
        uri: ${SOURCE_REPOSITORY_URL}
        ref: ${SOURCE_REPOSITORY_REF}
      type: Git
      secrets:
      - destinationDir: /opt/nuxeo/connect
        secret:
          name: ${APPLICATION_NAME}-connect
    strategy:
      type: Source
      sourceStrategy:
        from:
          kind: DockerImage
          name: 'nuxeo/s2i:${NUXEO_VERSION}'
        incremental: true      
    output:
      to:
        kind: ImageStreamTag
        name: ${APPLICATION_NAME}-app-build:latest
  successfulBuildsHistoryLimit: 2 
  failedBuildsHistoryLimit: 2 

- apiVersion: v1
  kind: BuildConfig
  metadata:
    name: ${APPLICATION_NAME}-app-assemble
    labels:
      app: ${APPLICATION_NAME}
      component: assembly
  spec:
    source:
      dockerfile: |-
        FROM ${APPLICATION_NAME}-base-image:latest
        USER root
        COPY build /build
        RUN chmod -R 777 /build
        USER 1000
        COPY ./connect.properties /opt/nuxeo/connect/connect.properties
        RUN /build/install.sh
        # Clean credential after using it
        USER root
        RUN rm -f /opt/nuxeo/connect/connect.properties && \
            rm -rf /opt/nuxeo/server/nxserver/config && \
            chgrp -fR 0 /opt/nuxeo/server/ && \
            chmod -fR g+rwX /opt/nuxeo/server/
        USER 1000
      images:
        - from:
            kind: ImageStreamTag
            name: ${APPLICATION_NAME}-app-build:latest
          paths:
            - destinationDir: .
              sourcePath: /build
      secrets:
        - destinationDir: ./
          secret:
            name: ${APPLICATION_NAME}-connect
      type: Dockerfile
    strategy:
      dockerStrategy:
        forcePull: true
        from:
          kind: ImageStreamTag
          name: ${APPLICATION_NAME}-base-image:latest
      type: Docker
    output:
      to:
        kind: ImageStreamTag
        name: '${APPLICATION_NAME}-nuxeo:latest'
    successfulBuildsHistoryLimit: 2 
    failedBuildsHistoryLimit: 2 




- apiVersion: v1
  kind: BuildConfig
  metadata:
    annotations:
      pipeline.alpha.openshift.io/uses: '[{"name": "${APPLICATION_NAME}", "namespace": "", "kind": "DeploymentConfig"}]'
    labels:
      name: ${APPLICATION_NAME}-pipeline
    name: ${APPLICATION_NAME}-pipeline
  spec:
    strategy:
      jenkinsPipelineStrategy:
        jenkinsfile: |-
          try {
             timeout(time: 60, unit: 'MINUTES') {
                node {
                    project = env.PROJECT_NAME
                    stage("init") {
                      sh "oc get route ${APPLICATION_NAME}-dev-nuxeo-route -n ${project} -o jsonpath='{ .spec.host }' --loglevel=4 > routehost"
                      routeHost = readFile('routehost').trim()
                    }

                    stage('build-app') {
                      openshiftBuild(buildConfig: '${APPLICATION_NAME}-app-build', showBuildLogs: 'true', waitTime: '1800000')
                    }

                    stage('assemble-app') {
                      openshiftBuild(buildConfig: '${APPLICATION_NAME}-app-assemble', showBuildLogs: 'true')
                    }

                    stage('deploy-dev') {
                      openshiftDeploy(deploymentConfig: '${APPLICATION_NAME}-dev-nuxeo')
                    }
                }
             }
             
            node {

                stage("validate") {
                  input message: "Test and validate deployment at http://${routeHost}. Approve?", id: "approval"
                }
            }
            timeout(time: 60, unit: 'MINUTES') {
                node {
                  stage('deploy-uat') {
                    openshiftDeploy(deploymentConfig: '${APPLICATION_NAME}-uat-nuxeo')
                  }
                }
            }
             
          } catch (err) {
             echo "in catch block"
             echo "Caught: ${err}"
             currentBuild.result = 'FAILURE'
             throw err
          }          
      type: JenkinsPipeline
    triggers:
    - github:
        secret: ${GITHUB_WEBHOOK_SECRET}
      type: GitHub
    successfulBuildsHistoryLimit: 10 
    failedBuildsHistoryLimit: 5

- apiVersion: v1
  kind: BuildConfig
  metadata:
    labels:
      name: ${APPLICATION-NAME}-reset-dev
    name: ${APPLICATION-NAME}-reset-dev
  spec:
    strategy:
      jenkinsPipelineStrategy:
        jenkinsfile: |-
          properties([
            [$class: 'BuildDiscarderProperty', strategy: [$class: 'LogRotator', daysToKeepStr: '5', numToKeepStr: '5', artifactNumToKeepStr: '1']]
          ])
          try {
            timeout(time: 60, unit: 'MINUTES') {
              node {
                stage("confirm") {
                  input message: "Do you really want to reset data for DEV environment ? All data will be lost !", id: "approval"
                }
              }
              node {
                project = env.PROJECT_NAME
                stage("stop nuxeo pod") {
                  sh "oc scale dc/${APPLICATION-NAME}-dev-nuxeo --replicas=0"
                }
                stage('drop db') {
                  sh "oc get pod -l component=mongo --template='{{range .items}}{{.metadata.name}}{{end}}' > podname"
                  podMongo = readFile('podname').trim()
                  sh '''oc exec ''' + podMongo + ''' -- bash -c 'mongo ${APPLICATION-NAME}-dev --eval "printjson(db.dropDatabase())"'   '''
                }
                stage('drop es indexes') {
                  sh "oc get pod -l component=elasticsearch --template='{{range .items}}{{.metadata.name}}{{end}}' > podname"
                  podElastic = readFile('podname').trim()
                  sh '''oc exec ''' + podElastic + ''' -- bash -c "curl -XDELETE http://localhost:9200/${APPLICATION-NAME}-dev-uidgen"'''
                  sh '''oc exec ''' + podElastic + ''' -- bash -c "curl -XDELETE http://localhost:9200/${APPLICATION-NAME}-dev-audit"'''
                  sh '''oc exec ''' + podElastic + ''' -- bash -c "curl -XDELETE http://localhost:9200/${APPLICATION-NAME}-dev"'''
                }
                stage("restart nuxeo pod") {
                  sh "oc scale dc/${APPLICATION-NAME}-dev-nuxeo --replicas=1"
                }
                stage("wait for pod") {
                    isAwait = true
                    while (isAwait) {
                      sh "oc get dc/${APPLICATION-NAME}-dev-nuxeo --template='{{.status.availableReplicas}}'  > status"
                      status = readFile('status').trim()
                      if (status.toString().equals("1")) {
                          isAwait = false
                      } else {
                          sleep(time: 30, unit: 'SECONDS')
                      }
                    }
                  }
              }
            }
          } catch (err) {
             echo "in catch block"
             echo "Caught: ${err}"
             currentBuild.result = 'FAILURE'
             throw err
          }

- apiVersion: v1
  kind: BuildConfig
  metadata:
    labels:
      name: ${APPLICATION-NAME}-reset-uat
    name: ${APPLICATION-NAME}-reset-uat
  spec:
    strategy:
      jenkinsPipelineStrategy:
        jenkinsfile: |-
          properties([
            [$class: 'BuildDiscarderProperty', strategy: [$class: 'LogRotator', daysToKeepStr: '5', numToKeepStr: '5', artifactNumToKeepStr: '1']]
          ])
          try {
            timeout(time: 60, unit: 'MINUTES') {
              node {
                stage("confirm") {
                  input message: "Do you really want to reset data for DEV environment ? All data will be lost !", id: "approval"
                }
              }
              node {
                project = env.PROJECT_NAME
                stage("stop nuxeo pod") {
                  sh "oc scale dc/${APPLICATION-NAME}-uat-nuxeo --replicas=0"
                }
                stage('drop db') {
                  sh "oc get pod -l component=mongo --template='{{range .items}}{{.metadata.name}}{{end}}' > podname"
                  podMongo = readFile('podname').trim()
                  sh '''oc exec ''' + podMongo + ''' -- bash -c 'mongo ${APPLICATION-NAME}-uat --eval "printjson(db.dropDatabase())"'   '''
                }
                stage('drop es indexes') {
                  sh "oc get pod -l component=elasticsearch --template='{{range .items}}{{.metadata.name}}{{end}}' > podname"
                  podElastic = readFile('podname').trim()
                  sh '''oc exec ''' + podElastic + ''' -- bash -c "curl -XDELETE http://localhost:9200/${APPLICATION-NAME}-uat-uidgen"'''
                  sh '''oc exec ''' + podElastic + ''' -- bash -c "curl -XDELETE http://localhost:9200/${APPLICATION-NAME}-uat-audit"'''
                  sh '''oc exec ''' + podElastic + ''' -- bash -c "curl -XDELETE http://localhost:9200/${APPLICATION-NAME}-uat"'''
                }
                stage("restart nuxeo pod") {
                  sh "oc scale dc/${APPLICATION-NAME}-uat-nuxeo --replicas=1"
                }
                stage("wait for pod") {
                    isAwait = true
                    while (isAwait) {
                      sh "oc get dc/${APPLICATION-NAME}-uat-nuxeo --template='{{.status.availableReplicas}}'  > status"
                      status = readFile('status').trim()
                      if (status.toString().equals("1")) {
                          isAwait = false
                      } else {
                          sleep(time: 30, unit: 'SECONDS')
                      }
                    }
                  }
              }
            }
          } catch (err) {
             echo "in catch block"
             echo "Caught: ${err}"
             currentBuild.result = 'FAILURE'
             throw err
          }